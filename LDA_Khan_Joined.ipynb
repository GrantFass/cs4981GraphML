{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi\n",
    "\n",
    "# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n",
    "import torch\n",
    "\n",
    "def format_pytorch_version(version):\n",
    "  return version.split('+')[0]\n",
    "\n",
    "TORCH_version = torch.__version__\n",
    "TORCH = format_pytorch_version(TORCH_version)\n",
    "\n",
    "def format_cuda_version(version):\n",
    "  return 'cu' + version.replace('.', '')\n",
    "\n",
    "CUDA_version = torch.version.cuda\n",
    "# CUDA = format_cuda_version(CUDA_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\past\\builtins\\misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "c:\\Python310\\lib\\site-packages\\joblib\\backports.py:7: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  from distutils.version import LooseVersion\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "# import uuid  # https://docs.python.org/3/library/uuid.html\n",
    "# import structlog  # for event logging\n",
    "# # from dotenv import load_dotenv # enviornment vars if we want\n",
    "\n",
    "# from pygtail import Pygtail\n",
    "# import boto3\n",
    "# from minio import Minio\n",
    "# from dotenv import load_dotenv\n",
    "from datetime import timedelta, datetime\n",
    "from time import sleep\n",
    "from sys import argv\n",
    "# import threading\n",
    "# from smart_open import smart_open\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "# setup to import the preprocessor\n",
    "import sys\n",
    "# from botocore.errorfactory import ClientError\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "pyLDAvis.enable_notebook()\n",
    "import torch_geometric\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Preprocessing import Preprocessor\n",
    "preprocessor = Preprocessor(0)\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>unit</th>\n",
       "      <th>lesson</th>\n",
       "      <th>video_title</th>\n",
       "      <th>about</th>\n",
       "      <th>transcript</th>\n",
       "      <th>topic</th>\n",
       "      <th>transcript_cleaned</th>\n",
       "      <th>transcript_n_entries</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>computer</td>\n",
       "      <td>Intro to JS: Drawing &amp; Animation</td>\n",
       "      <td>Intro to programming</td>\n",
       "      <td>What is Programming?</td>\n",
       "      <td>Programming is the process of creating a set o...</td>\n",
       "      <td>Hi, welcome to programming! If you've never le...</td>\n",
       "      <td>Computing</td>\n",
       "      <td>['Angry Birds', 'and of course', 'were giving ...</td>\n",
       "      <td>183</td>\n",
       "      <td>['hi,', 'welcome', 'programming!', 'never', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>computer</td>\n",
       "      <td>Intro to JS: Drawing &amp; Animation</td>\n",
       "      <td>Coloring</td>\n",
       "      <td>The Power of the Docs</td>\n",
       "      <td>Created by Pamela Fox.</td>\n",
       "      <td>Voiceover: Ok so you've\\r\\nmade a few programs...</td>\n",
       "      <td>Computing</td>\n",
       "      <td>['because 1 degree to 270 degrees,\\r\\nthats wh...</td>\n",
       "      <td>542</td>\n",
       "      <td>['voiceover:', 'ok', 'made', 'programs,', 'mig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computer</td>\n",
       "      <td>Intro to HTML/CSS: Making webpages</td>\n",
       "      <td>Further learning</td>\n",
       "      <td>HTML validation</td>\n",
       "      <td>Learn how to validate your webpages with the W...</td>\n",
       "      <td>- [Voiceover] On Khan Academy, we pop up the o...</td>\n",
       "      <td>Computing</td>\n",
       "      <td>['this is a classic thing to forget is that al...</td>\n",
       "      <td>172</td>\n",
       "      <td>['-', 'khan', 'academy,', 'pop', 'oh', 'noes',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>computer</td>\n",
       "      <td>Intro to SQL: Querying and managing data</td>\n",
       "      <td>SQL basics</td>\n",
       "      <td>Welcome to SQL</td>\n",
       "      <td>SQL is useful for creating and querying relati...</td>\n",
       "      <td>- [Instructor] The world is full of data. Ever...</td>\n",
       "      <td>Computing</td>\n",
       "      <td>['just by mapping user IDs to badge IDs. Thats...</td>\n",
       "      <td>203</td>\n",
       "      <td>['-', 'world', 'full', 'data.', 'every', 'app'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computer</td>\n",
       "      <td>Intro to SQL: Querying and managing data</td>\n",
       "      <td>SQL basics</td>\n",
       "      <td>S-Q-L or SEQUEL?</td>\n",
       "      <td>How is it pronounced? Why? Let's discuss...</td>\n",
       "      <td>At this point, you've probably heard me\\r\\npro...</td>\n",
       "      <td>Computing</td>\n",
       "      <td>['At this point', 'by pronouncing SQL the long...</td>\n",
       "      <td>129</td>\n",
       "      <td>['point,', 'probably', 'heard', 'pronounce', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     course                                      unit                lesson  \\\n",
       "0  computer          Intro to JS: Drawing & Animation  Intro to programming   \n",
       "1  computer          Intro to JS: Drawing & Animation              Coloring   \n",
       "2  computer        Intro to HTML/CSS: Making webpages      Further learning   \n",
       "3  computer  Intro to SQL: Querying and managing data            SQL basics   \n",
       "4  computer  Intro to SQL: Querying and managing data            SQL basics   \n",
       "\n",
       "             video_title                                              about  \\\n",
       "0   What is Programming?  Programming is the process of creating a set o...   \n",
       "1  The Power of the Docs                             Created by Pamela Fox.   \n",
       "2        HTML validation  Learn how to validate your webpages with the W...   \n",
       "3         Welcome to SQL  SQL is useful for creating and querying relati...   \n",
       "4       S-Q-L or SEQUEL?       How is it pronounced? Why? Let's discuss...    \n",
       "\n",
       "                                          transcript      topic  \\\n",
       "0  Hi, welcome to programming! If you've never le...  Computing   \n",
       "1  Voiceover: Ok so you've\\r\\nmade a few programs...  Computing   \n",
       "2  - [Voiceover] On Khan Academy, we pop up the o...  Computing   \n",
       "3  - [Instructor] The world is full of data. Ever...  Computing   \n",
       "4  At this point, you've probably heard me\\r\\npro...  Computing   \n",
       "\n",
       "                                  transcript_cleaned  transcript_n_entries  \\\n",
       "0  ['Angry Birds', 'and of course', 'were giving ...                   183   \n",
       "1  ['because 1 degree to 270 degrees,\\r\\nthats wh...                   542   \n",
       "2  ['this is a classic thing to forget is that al...                   172   \n",
       "3  ['just by mapping user IDs to badge IDs. Thats...                   203   \n",
       "4  ['At this point', 'by pronouncing SQL the long...                   129   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['hi,', 'welcome', 'programming!', 'never', 'l...  \n",
       "1  ['voiceover:', 'ok', 'made', 'programs,', 'mig...  \n",
       "2  ['-', 'khan', 'academy,', 'pop', 'oh', 'noes',...  \n",
       "3  ['-', 'world', 'full', 'data.', 'every', 'app'...  \n",
       "4  ['point,', 'probably', 'heard', 'pronounce', '...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_exists = os.path.exists('khan_joined.csv')\n",
    "khan = pd.DataFrame([])\n",
    "if joined_exists:\n",
    "    khan = pd.read_csv('khan_joined.csv')\n",
    "khan.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not joined_exists:\n",
    "    computing = pd.read_csv(\"Datasets\\\\KhanAcademy\\\\Computing.csv\")\n",
    "    computing = computing.dropna()\n",
    "    computing['topic'] = 'Computing'\n",
    "    computing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not joined_exists:\n",
    "    economics = pd.read_csv(\"Datasets\\\\KhanAcademy\\\\Economics.csv\")\n",
    "    economics = economics.dropna()\n",
    "    economics['topic'] = 'Economics'\n",
    "    economics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not joined_exists:\n",
    "    humanities = pd.read_csv(\"Datasets\\\\KhanAcademy\\\\Humanities.csv\")\n",
    "    humanities = humanities.dropna()\n",
    "    humanities['topic'] = 'Humanities'\n",
    "    humanities.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not joined_exists:\n",
    "    math = pd.read_csv(\"Datasets\\\\KhanAcademy\\\\Math.csv\")\n",
    "    math = math.dropna()\n",
    "    math['topic'] = 'Math'\n",
    "    math.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not joined_exists:\n",
    "    science = pd.read_csv(\"Datasets\\\\KhanAcademy\\\\Science.csv\")\n",
    "    science = science.dropna()\n",
    "    science['topic'] = 'Science'\n",
    "    science.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2461 entries, 0 to 2466\n",
      "Data columns (total 19 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   comments            2461 non-null   int64 \n",
      " 1   description         2461 non-null   object\n",
      " 2   duration            2461 non-null   int64 \n",
      " 3   event               2461 non-null   object\n",
      " 4   film_date           2461 non-null   int64 \n",
      " 5   languages           2461 non-null   int64 \n",
      " 6   main_speaker        2461 non-null   object\n",
      " 7   name                2461 non-null   object\n",
      " 8   num_speaker         2461 non-null   int64 \n",
      " 9   published_date      2461 non-null   int64 \n",
      " 10  ratings             2461 non-null   object\n",
      " 11  related_talks       2461 non-null   object\n",
      " 12  speaker_occupation  2461 non-null   object\n",
      " 13  tags                2461 non-null   object\n",
      " 14  title               2461 non-null   object\n",
      " 15  urlurl              2461 non-null   object\n",
      " 16  views               2461 non-null   int64 \n",
      " 17  transcript          2461 non-null   object\n",
      " 18  urlurl              2461 non-null   object\n",
      "dtypes: int64(7), object(12)\n",
      "memory usage: 384.5+ KB\n"
     ]
    }
   ],
   "source": [
    "ted_main = pd.read_csv(\"Datasets\\\\TEDTalksDataset\\\\ted_main.csv\")\n",
    "transcripts = pd.read_csv(\"Datasets\\\\TEDTalksDataset\\\\transcripts.csv\")\n",
    "validation = ted_main.join(transcripts, lsuffix='url', rsuffix='url', sort=True)\n",
    "validation = validation.dropna()\n",
    "validation.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not joined_exists:\n",
    "    computing['course'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not joined_exists:\n",
    "    economics['course'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not joined_exists:\n",
    "    humanities['course'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not joined_exists:\n",
    "    math['course'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not joined_exists:\n",
    "    science['course'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not joined_exists:\n",
    "    khan_dfs = [computing, economics, humanities, math, science]\n",
    "    khan = pd.concat(khan_dfs, axis=0)\n",
    "    khan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "algebra                                         1287\n",
       "calculus                                         947\n",
       "chemistry                                        909\n",
       "history                                          769\n",
       "biology                                          757\n",
       "physics                                          743\n",
       "statistics                                       626\n",
       "economics                                        502\n",
       "geometry                                         345\n",
       "Finance and capital markets                      317\n",
       "Electrical engineering                           198\n",
       "Pixar in a Box                                   175\n",
       "US government and civics                         139\n",
       "Cosmology and astronomy                           89\n",
       "AP®︎/College US Government and Politics           87\n",
       "Trigonometry                                      76\n",
       "computer                                          75\n",
       "Differential equations                            70\n",
       "Storytelling                                      69\n",
       "AP®︎/College Environmental science                49\n",
       "Middle school Earth and space science - NGSS      19\n",
       "Code.org                                          13\n",
       "Name: course, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if not joined_exists:\n",
    "# remap the courses to more broad categories: https://stackoverflow.com/a/16476974\n",
    "labels = ['physics', 'chemistry', 'biology', 'algebra', 'geometry', 'statistics', 'calculus', 'history', 'economics', 'computer']\n",
    "for lbl in labels:\n",
    "    # print(lbl)\n",
    "    for index, row in khan.iterrows():\n",
    "        if lbl in row['course'].lower():\n",
    "            row['course'] = lbl\n",
    "khan['course'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>unit</th>\n",
       "      <th>lesson</th>\n",
       "      <th>video_title</th>\n",
       "      <th>about</th>\n",
       "      <th>transcript</th>\n",
       "      <th>topic</th>\n",
       "      <th>transcript_cleaned</th>\n",
       "      <th>transcript_n_entries</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8259</th>\n",
       "      <td>physics</td>\n",
       "      <td>Review for AP Physics 1 exam</td>\n",
       "      <td>AP Physics 1 free response questions 2015</td>\n",
       "      <td>Question 4: 2015 AP Physics 1 free response</td>\n",
       "      <td>Identical spheres falling from the same height...</td>\n",
       "      <td>- [Voiceover] Two identical\\r\\nspheres are rel...</td>\n",
       "      <td>Science</td>\n",
       "      <td>['coherent', 'if we want. F sub G. Or we could...</td>\n",
       "      <td>673</td>\n",
       "      <td>['-', 'two', 'identical', 'spheres', 'released...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8260</th>\n",
       "      <td>physics</td>\n",
       "      <td>Review for AP Physics 1 exam</td>\n",
       "      <td>AP Physics 1 free response questions 2015</td>\n",
       "      <td>Question 5: 2015 AP Physics 1 free response</td>\n",
       "      <td>Fundamental frequencies (first harmonics) of s...</td>\n",
       "      <td>- [Voiceover] The figure\\r\\nabove shows a stri...</td>\n",
       "      <td>Science</td>\n",
       "      <td>['lets answer each of these. So a', 'the funda...</td>\n",
       "      <td>901</td>\n",
       "      <td>['-', 'figure', 'shows', 'string', 'one', 'end...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       course                          unit  \\\n",
       "8259  physics  Review for AP Physics 1 exam   \n",
       "8260  physics  Review for AP Physics 1 exam   \n",
       "\n",
       "                                         lesson  \\\n",
       "8259  AP Physics 1 free response questions 2015   \n",
       "8260  AP Physics 1 free response questions 2015   \n",
       "\n",
       "                                      video_title  \\\n",
       "8259  Question 4: 2015 AP Physics 1 free response   \n",
       "8260  Question 5: 2015 AP Physics 1 free response   \n",
       "\n",
       "                                                  about  \\\n",
       "8259  Identical spheres falling from the same height...   \n",
       "8260  Fundamental frequencies (first harmonics) of s...   \n",
       "\n",
       "                                             transcript    topic  \\\n",
       "8259  - [Voiceover] Two identical\\r\\nspheres are rel...  Science   \n",
       "8260  - [Voiceover] The figure\\r\\nabove shows a stri...  Science   \n",
       "\n",
       "                                     transcript_cleaned  transcript_n_entries  \\\n",
       "8259  ['coherent', 'if we want. F sub G. Or we could...                   673   \n",
       "8260  ['lets answer each of these. So a', 'the funda...                   901   \n",
       "\n",
       "                                                 tokens  \n",
       "8259  ['-', 'two', 'identical', 'spheres', 'released...  \n",
       "8260  ['-', 'figure', 'shows', 'string', 'one', 'end...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "khan.tail(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Identification\n",
    "It is necessary to now identify components of the dataset that can be used for the graphical machine learning. This means identifying Nodes, Edges, Node Features, and Labels. It also includes optionally including edge weights and edge features. For the sake of simplicity I think that I will be forgoing the edge weights and edge features.\n",
    "\n",
    "I am attempting to basically do topic modeling, but without the keywords and topics that would be customary of Latent Dirchlet Allocation. Instead the goal is to train a Graph ML model using the Khan academy data.\n",
    "\n",
    "There are two basic routes I could take. I could perform node level prediction by treating each transcript individually and seeing which is the closest match during prediction. The other option would be to perform graph level prediction by storing all of the similarly labeled transcripts together and then using the shape of the graph for comparison. \n",
    "\n",
    "- Nodes (Items, People, Locations, Cars, ETC)\n",
    "- Edges (Connections, Interactions, Similarity, ETC)\n",
    "    - Levenshtein distance over titles?\n",
    "    - Number of similar named entities from SpaCy NER?\n",
    "- Node Features (Attributes)\n",
    "- Labels (Node-Level, Edge-Level, Graph-Level, etc)\n",
    "    - I am going to first try node-level prediction as it makes more sense to me. For this I am going to use the 'course' feature in the above pandas dataframe. This will be the target that I try to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not joined_exists:\n",
    "    # It takes 21 min to run SpaCy preprocessing over each record in the data\n",
    "    khan['transcript_cleaned'] = khan['transcript'].progress_apply(lambda x: preprocessor.clean(x, fast=True))\n",
    "    print(khan['transcript_cleaned'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not joined_exists:\n",
    "    # clear up the lists to be unique only.\n",
    "    khan['tokens'] = khan['transcript'].progress_apply(lambda x: preprocessor.clean(x, tokenize=True, fast=True))\n",
    "    print(len(khan['tokens'][0]))\n",
    "    print(khan['tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not joined_exists:\n",
    "# if not False:\n",
    "    khan['transcript_n_entries'] = khan['tokens'].progress_apply(lambda x: len(x))\n",
    "    khan.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# khan = khan.drop(columns=[\"Unnamed: 0.1\", \"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>unit</th>\n",
       "      <th>lesson</th>\n",
       "      <th>video_title</th>\n",
       "      <th>about</th>\n",
       "      <th>transcript</th>\n",
       "      <th>topic</th>\n",
       "      <th>transcript_cleaned</th>\n",
       "      <th>transcript_n_entries</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>computer</td>\n",
       "      <td>Intro to JS: Drawing &amp; Animation</td>\n",
       "      <td>Intro to programming</td>\n",
       "      <td>What is Programming?</td>\n",
       "      <td>Programming is the process of creating a set o...</td>\n",
       "      <td>Hi, welcome to programming! If you've never le...</td>\n",
       "      <td>Computing</td>\n",
       "      <td>['Angry Birds', 'and of course', 'were giving ...</td>\n",
       "      <td>183</td>\n",
       "      <td>['hi,', 'welcome', 'programming!', 'never', 'l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     course                              unit                lesson  \\\n",
       "0  computer  Intro to JS: Drawing & Animation  Intro to programming   \n",
       "\n",
       "            video_title                                              about  \\\n",
       "0  What is Programming?  Programming is the process of creating a set o...   \n",
       "\n",
       "                                          transcript      topic  \\\n",
       "0  Hi, welcome to programming! If you've never le...  Computing   \n",
       "\n",
       "                                  transcript_cleaned  transcript_n_entries  \\\n",
       "0  ['Angry Birds', 'and of course', 'were giving ...                   183   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['hi,', 'welcome', 'programming!', 'never', 'l...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "khan.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not joined_exists:\n",
    "# if not False:\n",
    "    khan.to_csv(\"khan_joined.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    nodes closer to yourself are more important. Take the incoming embeddings and dotproduct them with your own embedding.\\n    Softmax across all the dot products of the nodes coming in to have it be a probability.\\n    \\n    Need to build the corpus of all input words.\\n    \\n    Use spacy to get corpus for each doc with stopwords stripped and bigrams / trigrams joined. \\n    \\n    Could use skipgram or bag of words with word2vec to embed words.\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/code/pavansanagapati/knowledge-graph-nlp-tutorial-bert-spacy-nltk/notebook\n",
    "\n",
    "\"\"\"\n",
    "    nodes closer to yourself are more important. Take the incoming embeddings and dotproduct them with your own embedding.\n",
    "    Softmax across all the dot products of the nodes coming in to have it be a probability.\n",
    "    \n",
    "    Need to build the corpus of all input words.\n",
    "    \n",
    "    Use spacy to get corpus for each doc with stopwords stripped and bigrams / trigrams joined. \n",
    "    \n",
    "    Could use skipgram or bag of words with word2vec to embed words.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>unit</th>\n",
       "      <th>lesson</th>\n",
       "      <th>video_title</th>\n",
       "      <th>about</th>\n",
       "      <th>transcript</th>\n",
       "      <th>topic</th>\n",
       "      <th>transcript_cleaned</th>\n",
       "      <th>transcript_n_entries</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>computer</td>\n",
       "      <td>Intro to JS: Drawing &amp; Animation</td>\n",
       "      <td>Intro to programming</td>\n",
       "      <td>What is Programming?</td>\n",
       "      <td>Programming is the process of creating a set o...</td>\n",
       "      <td>Hi, welcome to programming! If you've never le...</td>\n",
       "      <td>Computing</td>\n",
       "      <td>['Angry Birds', 'and of course', 'were giving ...</td>\n",
       "      <td>183</td>\n",
       "      <td>['hi,', 'welcome', 'programming!', 'never', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>computer</td>\n",
       "      <td>Intro to JS: Drawing &amp; Animation</td>\n",
       "      <td>Coloring</td>\n",
       "      <td>The Power of the Docs</td>\n",
       "      <td>Created by Pamela Fox.</td>\n",
       "      <td>Voiceover: Ok so you've\\r\\nmade a few programs...</td>\n",
       "      <td>Computing</td>\n",
       "      <td>['because 1 degree to 270 degrees,\\r\\nthats wh...</td>\n",
       "      <td>542</td>\n",
       "      <td>['voiceover:', 'ok', 'made', 'programs,', 'mig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computer</td>\n",
       "      <td>Intro to HTML/CSS: Making webpages</td>\n",
       "      <td>Further learning</td>\n",
       "      <td>HTML validation</td>\n",
       "      <td>Learn how to validate your webpages with the W...</td>\n",
       "      <td>- [Voiceover] On Khan Academy, we pop up the o...</td>\n",
       "      <td>Computing</td>\n",
       "      <td>['this is a classic thing to forget is that al...</td>\n",
       "      <td>172</td>\n",
       "      <td>['-', 'khan', 'academy,', 'pop', 'oh', 'noes',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>computer</td>\n",
       "      <td>Intro to SQL: Querying and managing data</td>\n",
       "      <td>SQL basics</td>\n",
       "      <td>Welcome to SQL</td>\n",
       "      <td>SQL is useful for creating and querying relati...</td>\n",
       "      <td>- [Instructor] The world is full of data. Ever...</td>\n",
       "      <td>Computing</td>\n",
       "      <td>['just by mapping user IDs to badge IDs. Thats...</td>\n",
       "      <td>203</td>\n",
       "      <td>['-', 'world', 'full', 'data.', 'every', 'app'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computer</td>\n",
       "      <td>Intro to SQL: Querying and managing data</td>\n",
       "      <td>SQL basics</td>\n",
       "      <td>S-Q-L or SEQUEL?</td>\n",
       "      <td>How is it pronounced? Why? Let's discuss...</td>\n",
       "      <td>At this point, you've probably heard me\\r\\npro...</td>\n",
       "      <td>Computing</td>\n",
       "      <td>['At this point', 'by pronouncing SQL the long...</td>\n",
       "      <td>129</td>\n",
       "      <td>['point,', 'probably', 'heard', 'pronounce', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     course                                      unit                lesson  \\\n",
       "0  computer          Intro to JS: Drawing & Animation  Intro to programming   \n",
       "1  computer          Intro to JS: Drawing & Animation              Coloring   \n",
       "2  computer        Intro to HTML/CSS: Making webpages      Further learning   \n",
       "3  computer  Intro to SQL: Querying and managing data            SQL basics   \n",
       "4  computer  Intro to SQL: Querying and managing data            SQL basics   \n",
       "\n",
       "             video_title                                              about  \\\n",
       "0   What is Programming?  Programming is the process of creating a set o...   \n",
       "1  The Power of the Docs                             Created by Pamela Fox.   \n",
       "2        HTML validation  Learn how to validate your webpages with the W...   \n",
       "3         Welcome to SQL  SQL is useful for creating and querying relati...   \n",
       "4       S-Q-L or SEQUEL?       How is it pronounced? Why? Let's discuss...    \n",
       "\n",
       "                                          transcript      topic  \\\n",
       "0  Hi, welcome to programming! If you've never le...  Computing   \n",
       "1  Voiceover: Ok so you've\\r\\nmade a few programs...  Computing   \n",
       "2  - [Voiceover] On Khan Academy, we pop up the o...  Computing   \n",
       "3  - [Instructor] The world is full of data. Ever...  Computing   \n",
       "4  At this point, you've probably heard me\\r\\npro...  Computing   \n",
       "\n",
       "                                  transcript_cleaned  transcript_n_entries  \\\n",
       "0  ['Angry Birds', 'and of course', 'were giving ...                   183   \n",
       "1  ['because 1 degree to 270 degrees,\\r\\nthats wh...                   542   \n",
       "2  ['this is a classic thing to forget is that al...                   172   \n",
       "3  ['just by mapping user IDs to badge IDs. Thats...                   203   \n",
       "4  ['At this point', 'by pronouncing SQL the long...                   129   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['hi,', 'welcome', 'programming!', 'never', 'l...  \n",
       "1  ['voiceover:', 'ok', 'made', 'programs,', 'mig...  \n",
       "2  ['-', 'khan', 'academy,', 'pop', 'oh', 'noes',...  \n",
       "3  ['-', 'world', 'full', 'data.', 'every', 'app'...  \n",
       "4  ['point,', 'probably', 'heard', 'pronounce', '...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "khan.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "algebra                                         1287\n",
       "calculus                                         947\n",
       "chemistry                                        909\n",
       "history                                          769\n",
       "biology                                          757\n",
       "physics                                          743\n",
       "statistics                                       626\n",
       "economics                                        502\n",
       "geometry                                         345\n",
       "Finance and capital markets                      317\n",
       "Electrical engineering                           198\n",
       "Pixar in a Box                                   175\n",
       "US government and civics                         139\n",
       "Cosmology and astronomy                           89\n",
       "AP®︎/College US Government and Politics           87\n",
       "Trigonometry                                      76\n",
       "computer                                          75\n",
       "Differential equations                            70\n",
       "Storytelling                                      69\n",
       "AP®︎/College Environmental science                49\n",
       "Middle school Earth and space science - NGSS      19\n",
       "Code.org                                          13\n",
       "Name: course, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "khan['course'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# khan['transcript_cleaned'] = khan['transcript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = khan['tokens'].sum(axis=0)\n",
    "if isinstance(corpus, str):\n",
    "    # means it performed string concatenation so it needs to be cleaned up\n",
    "    print(corpus[0:100])\n",
    "    # corpus = str_to_list(corpus)\n",
    "    print(corpus[0: 25])\n",
    "    print(len(corpus))\n",
    "    print(type(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380582\n",
      "['', 'maybe to the same bank,\\r\\nmaybe a different bank. But it might now have\\r\\na different interest rate', 'so if we input a into our function then we output -6. f of a is -6. We input b we get three,\\r\\nwe input c we get -6', 'lets see. 11 times 12 is 121. And then 121 - 1 is going to be', 'maybe,\\r\\nas a sound wave', 'so thats\\r\\nthe same thing as-- actually let me just write it this way--\\r\\nthis is the same thing as 6 to the-- instead of 1/2,\\r\\nwe can write it as 5/10. Plus 3/5 is the same\\r\\nthing as 6/10 power', 'and at negative seven', 'which was shorter', 'I learned about computer\\r\\ngraphics in college because I loved animation. I wasnt crazy about computers', 'thats the Greek letter delta,\\r\\nshorthand for \"change in,\" well', 'when I multiply them,\\r\\nequal 64', 'sometimes youll see them in\\r\\nthese space-filling model', 'if I plot this on a curve', 'when they talk about inflation', 'and so you see these\\r\\nobligations essentially just growing dramatically. On top of that', 'you\\r\\nwould say $6.00 per share', 'we once again just multiply the 8 times\\r\\nthe whole expression. So its 8x plus 40\\r\\nover x plus 2. Now', 'you have the story of\\r\\nJoseph', 'then I\\r\\nthink you should worry about the moral hazard issues. But lets say this is Bank\\r\\nA', 'they love it. Because every time they do a\\r\\ntransaction', '100\\r\\nyears down the future it might allow the society\\r\\nto thrive or whatever else. So Ill leave you there.', 'early life had to metabolize', 'it would also be zero\\r\\nplus x', 'I can shift it and put it right over there and I think you see what is going on right now. Now all of these sides combined are going to be the same as this side kind of building', 'so its gonna be 0.050. So 0.050 moles of electrons. So you can see']\n"
     ]
    }
   ],
   "source": [
    "# convert the corpus to a set since there should be no unique values\n",
    "corpus = set(corpus)\n",
    "print(len(corpus))\n",
    "corpus = list(corpus)\n",
    "print(corpus[0:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "num_topics = len(khan['course'].value_counts())\n",
    "print(num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "CPU times: total: 15.4 s\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LDA Normal\n",
    "temp = [d.split() for d in corpus]\n",
    "print(type(temp))\n",
    "words = corpora.Dictionary(temp)\n",
    "words.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "corpus = [words.doc2bow(doc) for doc in temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\gensim\\models\\ldamodel.py:520\u001b[0m, in \u001b[0;36mLdaModel.__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    518\u001b[0m use_numpy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatcher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    519\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 520\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(corpus, chunks_as_numpy\u001b[39m=\u001b[39;49muse_numpy)\n\u001b[0;32m    521\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_lifecycle_event(\n\u001b[0;32m    522\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcreated\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    523\u001b[0m     msg\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrained \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    524\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\gensim\\models\\ldamodel.py:1005\u001b[0m, in \u001b[0;36mLdaModel.update\u001b[1;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[0;32m   1000\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1001\u001b[0m     logger\u001b[39m.\u001b[39minfo(\n\u001b[0;32m   1002\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPROGRESS: pass \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m, at document #\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1003\u001b[0m         pass_, chunk_no \u001b[39m*\u001b[39m chunksize \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(chunk), lencorpus\n\u001b[0;32m   1004\u001b[0m     )\n\u001b[1;32m-> 1005\u001b[0m     gammat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_estep(chunk, other)\n\u001b[0;32m   1007\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimize_alpha:\n\u001b[0;32m   1008\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_alpha(gammat, rho())\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\gensim\\models\\ldamodel.py:767\u001b[0m, in \u001b[0;36mLdaModel.do_estep\u001b[1;34m(self, chunk, state)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    766\u001b[0m     state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\n\u001b[1;32m--> 767\u001b[0m gamma, sstats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference(chunk, collect_sstats\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    768\u001b[0m state\u001b[39m.\u001b[39msstats \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m sstats\n\u001b[0;32m    769\u001b[0m state\u001b[39m.\u001b[39mnumdocs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m gamma\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]  \u001b[39m# avoids calling len(chunk) on a generator\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\gensim\\models\\ldamodel.py:718\u001b[0m, in \u001b[0;36mLdaModel.inference\u001b[1;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[0;32m    714\u001b[0m lastgamma \u001b[39m=\u001b[39m gammad\n\u001b[0;32m    715\u001b[0m \u001b[39m# We represent phi implicitly to save memory and time.\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# Substituting the value of the optimal phi back into\u001b[39;00m\n\u001b[0;32m    717\u001b[0m \u001b[39m# the update for gamma gives this update. Cf. Lee&Seung 2001.\u001b[39;00m\n\u001b[1;32m--> 718\u001b[0m gammad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m+\u001b[39m expElogthetad \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39;49mdot(cts \u001b[39m/\u001b[39;49m phinorm, expElogbetad\u001b[39m.\u001b[39;49mT)\n\u001b[0;32m    719\u001b[0m Elogthetad \u001b[39m=\u001b[39m dirichlet_expectation(gammad)\n\u001b[0;32m    720\u001b[0m expElogthetad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(Elogthetad)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=words,\n",
    "                                           num_topics=num_topics,\n",
    "                                           random_state=2,\n",
    "                                           update_every=1,\n",
    "                                           passes=15,\n",
    "                                           alpha='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, words, mds='mmds', R=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_corpus = words.doc2bow(validation['transcript'][0].split())\n",
    "print(len(new_text_corpus))\n",
    "prediction = lda_model.get_document_topics(new_text_corpus)\n",
    "prediction.sort(key = lambda x: x[1], reverse = True)\n",
    "print(prediction)\n",
    "prediction = prediction[0][0]\n",
    "print(\"Predicted Topic: %d\" % prediction)\n",
    "lda_model.show_topic(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
